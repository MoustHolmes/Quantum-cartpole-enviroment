{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoustHolmes/Quantum-cartpole-enviroment/blob/master/DQN_Cartpole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMdvqRvh6sEq"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct8iaY_lmclf"
      },
      "source": [
        "observation = env_openAI.reset()\r\n",
        "    \r\n",
        "done =False\r\n",
        "score = 0\r\n",
        "loss_this_game = []\r\n",
        "q_val_this_game = []\r\n",
        "greedy_this_game = []\r\n",
        "obs_this_game = []\r\n",
        "reward_this_game = []\r\n",
        "\r\n",
        "while not done:\r\n",
        "#         env_openAI.render()\r\n",
        "\r\n",
        "    action, q_vals, greedy = agent.choose_action(observation)\r\n",
        "    \r\n",
        "    q_val_this_game.append(q_vals)\r\n",
        "    greedy_this_game.append(greedy)\r\n",
        "    \r\n",
        "    observation_, reward, done, _= env_openAI.step(action) #i have deleted info\r\n",
        "    \r\n",
        "    obs_this_game.append(observation_)\r\n",
        "    \r\n",
        "    score += reward\r\n",
        "    reward_this_game.append(reward)\r\n",
        "    \r\n",
        "    agent.remember(observation, action, reward, observation_, done)\r\n",
        "    observation = observation_\r\n",
        "    \r\n",
        "    loss = agent.learn()\r\n",
        "    loss_this_game.append(loss)\r\n",
        "    \r\n",
        "obs_list.append(obs_this_game)\r\n",
        "reward_list.append(reward_this_game)\r\n",
        "q_val_list.append(q_val_this_game)\r\n",
        "greedy_list.append(greedy_this_game)\r\n",
        "loss_list.append(loss_this_game)\r\n",
        "eps_history.append(agent.epsilon)\r\n",
        "scores.append(score)\r\n",
        "\r\n",
        "#     avg_score = np.mean(scores[max(0,i-100):(i+1)])\r\n",
        "#     print('episode ', i,'score %.2f' %score,\r\n",
        "#          'average score %.2f' % avg_score)\r\n",
        "\r\n",
        "if i % 10 == 0 and i > 0:\r\n",
        "        file_name= 'Cart_pole_' +str(n_dense1)+'_'+str(n_dense2)+'_'+str(i)\r\n",
        "        agent.save_model_JSON(file_name)\r\n",
        "        avg_score = np.mean(scores[max(0,i-100):(i+1)])\r\n",
        "        print('episode ', i,'score %.2f' %score,\r\n",
        "              'average score %.2f' % avg_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1KEIwbxUy5H"
      },
      "source": [
        "save test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjZ64OXsn4Il"
      },
      "source": [
        "test"
      ]
    }
  ]
}